{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general libraries\n",
    "\n",
    "import itertools\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "import math\n",
    "import time\n",
    "import json\n",
    "from sklearn.svm import LinearSVC\n",
    "from joblib import dump, load\n",
    "from numba import jit, njit\n",
    "import numba\n",
    "\n",
    "# specific libraries\n",
    "\n",
    "from PlotToImage import PlotToImage\n",
    "from auto_tsmo import full_method\n",
    "from feature_extraction import getFeaturesVector\n",
    "from feature_extraction import getFeatures\n",
    "from FpsCounter import FpsCounter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization functions\n",
    "\n",
    "def ImShow(im, size=(14,17)):\n",
    "    plt.figure(figsize = size)\n",
    "    plt.imshow(im, 'gray')\n",
    "    plt.show()\n",
    "\n",
    "def HistPlot(vals, size=(14,17)):\n",
    "    plt.figure(figsize = size)\n",
    "    plt.plot(np.arange(len(vals)), vals)\n",
    "    plt.show()\n",
    "    \n",
    "def plot_histogram(vals):\n",
    "    x = list(range(len(vals)))\n",
    "    ax = plt.gca()\n",
    "    ax.bar(x, vals)\n",
    "    ax.set_xticks(x)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit('b1[:](f8[:],f8)')\n",
    "def symm(array, perc):\n",
    "    '''\n",
    "    finds and returns high symmetry vertical regions\n",
    "    '''\n",
    "    array /= np.max(array)\n",
    "    \n",
    "    pairs = []\n",
    "    for i in range(len(array)):\n",
    "        for j in range(i, min(i + len(array)//3, len(array))):\n",
    "            if abs(array[i]-array[j]) < perc and (array[i] != 0 and array[j] != 0):\n",
    "                pairs.append([i,j])\n",
    "    sym = pairs\n",
    "    \n",
    "    new_dens = np.ones(len(array))\n",
    "\n",
    "    for i in range(len(sym)):\n",
    "        if (sym[i][0] + sym[i][1]) % 2 == 0:\n",
    "            k = int(((sym[i][1] - sym[i][0])/2) + sym[i][0])\n",
    "            new_dens[k] *= 1 + (array[k]/max(array))\n",
    "        else:\n",
    "            k = int((((sym[i][1] - sym[i][0])/2) - .5) + sym[i][0])\n",
    "            new_dens[k] *= 1 + (array[k]/max(array))\n",
    "            new_dens[k+1] *= 1 + (array[k]/max(array))\n",
    "    \n",
    "    return new_dens > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit('f8[:](u1[:,:],i4,i4)')\n",
    "def whiteDensity(im, n, val):\n",
    "    '''\n",
    "    returns histogram containing sums of HIGH ENOUGH pixels intensities column-wise\n",
    "    '''\n",
    "    #new_im = cv2.threshold(im, val, 255, cv2.THRESH_BINARY)[1]\n",
    "    new_im = (im > val).astype(numba.int8)\n",
    "    den = np.array([np.sum(np.array([np.sum(np.array([new_im[j,i] for j in range(im.shape[0])])) for i in range(k, k+n)])) for k in range(0, im.shape[1], n)])\n",
    "    den = den / np.max(den)\n",
    "    return den"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit('f8[:](u1[:,:],i4)')\n",
    "def grayDensity(im, n):\n",
    "    '''\n",
    "    returns histogram containing sums of pixels intensities column-wise\n",
    "    '''\n",
    "    new_im = im\n",
    "    den = np.array([np.sum(np.array([np.sum(np.array([new_im[j,i] for j in range(im.shape[0])])) for i in range(k, k+n)])) for k in range(0, im.shape[1], n)])\n",
    "    den = den / np.max(den)\n",
    "    return den"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit('b1(u1[:,:])')\n",
    "def isCorrect(reg):\n",
    "    '''\n",
    "    Filtering contours by relative mean intensity value and \n",
    "    difference between the warmest and the coldest pixel intensity value\n",
    "    '''\n",
    "    den = grayDensity(reg, 1)\n",
    "    min_val = den.min()\n",
    "    int_val = reg.sum() / (reg.shape[0] * reg.shape[1])\n",
    "    if min_val < 0.75:\n",
    "        if int_val > 80:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRegionsAndMasks(im, im_mask, return_regions = True):\n",
    "    '''\n",
    "    returns regions and their coordinates (reg_masks) from image and given mask\n",
    "    '''\n",
    "    reg_masks = []\n",
    "    mask = []\n",
    "    for i, s in enumerate(im_mask):\n",
    "        if s:\n",
    "            mask.extend([i])\n",
    "        else:\n",
    "            if len(mask) > 5:\n",
    "                reg_masks.append(mask)\n",
    "            mask = []\n",
    "    if len(mask) > 10:\n",
    "        reg_masks.append(mask)\n",
    "    if not return_regions:\n",
    "        return reg_masks\n",
    "    regions = [np.array([[im[i,j] for j in mask] for i in range(im.shape[0])], dtype=np.uint8) for mask in reg_masks]\n",
    "    return regions, reg_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "gts_folder = \"Groundtruth_Markup//\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_dataset = {}\n",
    "with open(gts_folder + \"VIDEO_val_groundtruth.json\", \"r\") as read_file:\n",
    "    video_dataset = json.load(read_file)\n",
    "    \n",
    "FLIR_dataset = {}\n",
    "with open(gts_folder + \"FLIR_val_groundtruth.json\", \"r\") as read_file:\n",
    "    FLIR_dataset = json.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video_dataset = {}\n",
    "# with open(gts_folder + \"VIDEO_train_groundtruth.json\", \"r\") as read_file:\n",
    "#     video_dataset = json.load(read_file)\n",
    "    \n",
    "# FLIR_dataset = {}\n",
    "# with open(gts_folder + \"FLIR_train_groundtruth.json\", \"r\") as read_file:\n",
    "#     FLIR_dataset = json.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_model = load('video_classifier')\n",
    "FLIR_model = load('FLIR_classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRects(regions, reg_masks):\n",
    "    '''\n",
    "    finds and returns filtered rects (ROIs) from all vertical regions\n",
    "    '''\n",
    "    filtered_cnts = []\n",
    "    for i, reg in enumerate(regions):\n",
    "        thresholds, masks = full_method(reg, L = 2**8, M=128)\n",
    "        thresh = (((masks[-2]+masks[-1])*255)).astype(np.uint8)\n",
    "#         kernel = np.ones((3,3), np.uint8); thresh = cv2.dilate(thresh, kernel, iterations=10) \n",
    "#         kernel = np.array([[0.01, 1, 0.01], [0.01, 0.01, 0.01], [0.01, 1, 0.01]], np.float32);thresh = cv2.dilate(thresh, kernel, iterations=13)\n",
    "        thresh = cv2.threshold(...,190, )\n",
    "        kernel = np.array([[0, 1, 0], [0, 1, 0], [0, 1, 0]], np.uint8);\n",
    "        thresh = cv2.dilate(thresh, kernel, iterations=15)\n",
    "        kernel = np.array([[0, 0, 0], [1, 1, 1], [0, 0, 0]], np.uint8);thresh = cv2.dilate(thresh, kernel, iterations=10)\n",
    "    \n",
    "#         ImShow(reg)\n",
    "#         ImShow(thresh)\n",
    "        \n",
    "        \n",
    "        contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        for cnt in contours:\n",
    "            x,y,w,h = cv2.boundingRect(cnt)\n",
    "            if not (w > 10 and h > 20 and h / w > 0.5 and h / w < 3):\n",
    "                continue\n",
    "            if not isCorrect(reg[y:y+h,x:x+w]):\n",
    "                continue\n",
    "            x += reg_masks[i][0]\n",
    "            filtered_cnts.append([x,y,w,h])\n",
    "            \n",
    "    return filtered_cnts \n",
    "\n",
    "def filterRects(im_path, rects, video_or_FLIR):\n",
    "    '''\n",
    "    returns rects filtered by corresponding classifier\n",
    "    '''\n",
    "    if video_or_FLIR == 'video':\n",
    "        model = video_model\n",
    "    elif video_or_FLIR == 'FLIR':\n",
    "        model = FLIR_model\n",
    "    else:\n",
    "        model = None\n",
    "    true_rects = []\n",
    "    for rect in rects:\n",
    "        if bool(model.predict(getFeatures((im_path, rect), True, True))):\n",
    "            true_rects.append(rect)\n",
    "    return true_rects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawRects(frame, rects):\n",
    "    '''\n",
    "    draws rects on given frame\n",
    "    '''\n",
    "    for rect in rects:\n",
    "        x,y,w,h = rect\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0,255,0), 2)\n",
    "\n",
    "def saveRects(rects, im_path, predictions):\n",
    "    '''\n",
    "    adds rects to given dict\n",
    "    '''\n",
    "    for rect in rects:\n",
    "        if im_path in predictions:\n",
    "            predictions[im_path].append(rect)\n",
    "        else:\n",
    "            predictions[im_path] = []\n",
    "            predictions[im_path].append(rect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit('b1[:](u1[:,:],i8)')\n",
    "def getSymm_(im, thresh_val):\n",
    "    '''\n",
    "    finds symmetry on given image and returns symmetry mask and corresponding image\n",
    "    '''\n",
    "    N = 8\n",
    "    den = whiteDensity(im, n = N, val = thresh_val)  \n",
    "\n",
    "    sym = symm(den, 0.1)\n",
    "    sym = np.array([[sym[i] for j in range(N)] for i in range(len(sym))]).reshape(-1,) \n",
    "    \n",
    "    return sym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSymm(im):\n",
    "    '''\n",
    "    finds symmetry on given image and returns symmetry mask and corresponding image\n",
    "    '''\n",
    "    thresholds, masks = full_method(im, L = 2**8, M=128)\n",
    "    thresh_val = thresholds[-1]\n",
    "\n",
    "    return getSymm_(im, thresh_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSymmImage(im, sym):\n",
    "    '''\n",
    "    finds symmetry on given image and returns symmetry mask and corresponding image\n",
    "    '''\n",
    "    sym_im = np.array([[im[i,j] for j in range(im.shape[1])]*sym for i in range(im.shape[0])], dtype = np.uint8)\n",
    "    \n",
    "    return sym_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_text_to_frame(frame, text):\n",
    "    '''\n",
    "    draws given text on given frame\n",
    "    '''\n",
    "    cv2.putText(frame, text, (20, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), lineType=cv2.LINE_AA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalSize(rects, frame, im):\n",
    "    height_ratio = frame.shape[0] / im.shape[0]\n",
    "    width_ratio = frame.shape[1] / im.shape[1]\n",
    "    \n",
    "    new_rects = []\n",
    "    \n",
    "    for (x,y,w,h) in rects:\n",
    "        x_max, y_max = x + w, y + h\n",
    "        \n",
    "        new_x = int(np.round(x * width_ratio))\n",
    "        new_y = int(np.round(y * height_ratio))\n",
    "        \n",
    "        new_x_max = int(np.round(x_max * width_ratio))\n",
    "        new_y_max = int(np.round(y_max * height_ratio))\n",
    "        \n",
    "        new_rects.append((new_x, new_y, new_x_max - new_x, new_y_max - new_y))\n",
    "        \n",
    "    return new_rects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Predict(dataset, SVM_filter = True, start_index = 0, end_index = None, show_fps = False, \n",
    "            show_blank_frame = True, show_symm_im = False, \n",
    "            time_between_frames = 1000, write_to_file = False, show_frame_index = True,\n",
    "            return_preds = False, resize = False):\n",
    "    \n",
    "    predictions = {}\n",
    "    \n",
    "    fps = FpsCounter()\n",
    "\n",
    "    index = -1\n",
    "    \n",
    "    dataset_keys = []\n",
    "    if dataset == 'VIDEO':\n",
    "        dataset_keys = list(video_dataset.keys())\n",
    "    elif dataset == 'FLIR':\n",
    "        dataset_keys = list(FLIR_dataset.keys())\n",
    "    else:\n",
    "        assert(False)\n",
    "    \n",
    "    \n",
    "    for im_path in dataset_keys:\n",
    "        if show_fps:\n",
    "            fps.start()\n",
    "        \n",
    "        index += 1\n",
    "        if (index < start_index):\n",
    "            continue\n",
    "            \n",
    "        frame = cv2.imread(im_path)\n",
    "        \n",
    "#         frame = cv2.resize(frame, (frame.shape[1] // 2, frame.shape[0] // 2))\n",
    "\n",
    "        im = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "        if resize:\n",
    "            k = 1\n",
    "            new_width = int(im.shape[1] / k)\n",
    "            new_width -= new_width % 8\n",
    "            \n",
    "            new_height = int(im.shape[0] / k)\n",
    "            new_height -= new_height % 8\n",
    "            \n",
    "            im = cv2.resize(im, (new_width, new_height))\n",
    "        \n",
    "        if show_blank_frame:\n",
    "            cv2.imshow(\"im\", im)\n",
    "\n",
    "        sym = getSymm(im)\n",
    "        \n",
    "        if show_symm_im:\n",
    "            sym_im = getSymmImage(im, sym)\n",
    "            cv2.imshow(\"symm_im\", sym_im)\n",
    "            \n",
    "        regions, reg_masks = getRegionsAndMasks(im, sym)\n",
    "        \n",
    "        rects = getRects(regions, reg_masks)\n",
    "        \n",
    "        if SVM_filter:\n",
    "            if dataset == 'VIDEO':\n",
    "                rects = filterRects(im_path, rects, 'video')\n",
    "            elif dataset == 'FLIR':\n",
    "                rects = filterRects(im_path, rects, 'FLIR')\n",
    "            else:\n",
    "                assert(False)\n",
    "                \n",
    "        if resize:\n",
    "            rects = normalSize(rects, frame, im)\n",
    "            \n",
    "        drawRects(frame, rects)\n",
    "        \n",
    "        saveRects(rects, im_path, predictions)\n",
    "\n",
    "        if show_fps:\n",
    "            fps.add_fps(frame)\n",
    "        \n",
    "        if show_frame_index:\n",
    "            add_text_to_frame(frame, im_path[-21:])\n",
    "            \n",
    "        cv2.imshow('frame', frame)\n",
    "\n",
    "        if cv2.waitKey(time_between_frames) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    if write_to_file:\n",
    "        if dataset == 'VIDEO':\n",
    "            if SVM_filter:\n",
    "                with open(preds_folder + 'VIDEO_val_predictions_SVM.json', 'w') as outfile:\n",
    "                    json.dump(predictions, outfile)\n",
    "            else:\n",
    "                with open(preds_folder + 'VIDEO_val_predictions.json', 'w') as outfile:\n",
    "                    json.dump(predictions, outfile)\n",
    "        elif dataset == 'FLIR':\n",
    "            if SVM_filter:\n",
    "                with open(preds_folder + 'FLIR_val_predictions_SVM.json', 'w') as outfile:\n",
    "                    json.dump(predictions, outfile)\n",
    "            else:\n",
    "                with open(preds_folder + 'FLIR_val_predictions.json', 'w') as outfile:\n",
    "                    json.dump(predictions, outfile)\n",
    "        else:\n",
    "            assert(False)\n",
    "    \n",
    "    if return_preds:\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = Predict(dataset = 'FLIR', SVM_filter = False, start_index = 0, end_index = None, show_fps = True, \n",
    "        show_blank_frame = True, show_symm_im = False, \n",
    "        time_between_frames = 1, write_to_file = False, show_frame_index = True, \n",
    "        return_preds = True, resize = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(preds_folder + 'VIDEO_val_predictions_TSMO_exp1.json', 'w') as outfile:\n",
    "    json.dump(predictions, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = Predict(dataset = 'FLIR', SVM_filter = False, start_index = 0, end_index = None, show_fps = True, \n",
    "        show_blank_frame = True, show_symm_im = False, \n",
    "        time_between_frames = 1, write_to_file = False, show_frame_index = True, \n",
    "        return_preds = True, resize = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(preds_folder + 'FLIR_val_predictions_TSMO_exp.json', 'w') as outfile:\n",
    "    json.dump(predictions, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just plain SSD Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plain_SSD_predict(dataset, write_to_file = False):\n",
    "    path = r'C:\\Users\\Yuriy\\Net2//'\n",
    "    \n",
    "    if dataset == 'VIDEO':\n",
    "        PATH_TO_CKPT = path + '/ssd_mobilenet_v2_coco_2020_02_02/frozen_inference_graph.pb'\n",
    "        dataset_keys = list(video_dataset.keys())\n",
    "    elif dataset == 'FLIR':\n",
    "        PATH_TO_CKPT = path + '/ssd_mobilenet_v2_coco_2020_02_17/frozen_inference_graph.pb'\n",
    "        dataset_keys = list(FLIR_dataset.keys())\n",
    "    else:\n",
    "        assert(False)\n",
    "\n",
    "    predictions = {}\n",
    "\n",
    "    fps = FpsCounter()\n",
    "\n",
    "    detection_graph = tf.Graph()\n",
    "    with detection_graph.as_default():\n",
    "        od_graph_def = tf.GraphDef()\n",
    "        with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "            serialized_graph = fid.read()\n",
    "            od_graph_def.ParseFromString(serialized_graph)\n",
    "            tf.import_graph_def(od_graph_def, name='')\n",
    "\n",
    "    with detection_graph.as_default():\n",
    "        with tf.Session(graph=detection_graph) as sess:\n",
    "\n",
    "            for im_path in dataset_keys:\n",
    "                fps.start()\n",
    "                frame = cv2.imread(im_path)\n",
    "                cv2.imshow(\"frame\", frame)\n",
    "\n",
    "                rows = frame.shape[0]\n",
    "                cols = frame.shape[1]\n",
    "                # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "                image_np_expanded = np.expand_dims(frame, axis=0)\n",
    "                image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "                # Each box represents a part of the image where a particular object was detected.\n",
    "                boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "                # Each score represent how level of confidence for each of the objects.\n",
    "                # Score is shown on the result image, together with the class label.\n",
    "                scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "                classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "                num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "\n",
    "                # Using Actual detection.\n",
    "                (boxes, scores, classes, num_detections) = sess.run(\n",
    "                    [boxes, scores, classes, num_detections],\n",
    "                    feed_dict={image_tensor: image_np_expanded})\n",
    "                #print(\"detected = \"+str(num_detections[0]))\n",
    "                boxes = np.squeeze(boxes)\n",
    "                scores = np.squeeze(scores)\n",
    "                # Visualize only detected boxes\n",
    "\n",
    "                rects = []\n",
    "\n",
    "                if (num_detections>0):\n",
    "                    for i in range(0,int(num_detections[0])):\n",
    "                        # Check scores for visualise\n",
    "                        if scores[i] < 0.2:\n",
    "                            continue\n",
    "                        detection = boxes[i]\n",
    "                        #print(str(detection) +' score='+ str(scores[i] ) + ' cols='+str(cols) + ' rows='+str(rows))\n",
    "                        left = detection[1] * cols\n",
    "                        top = detection[0] * rows\n",
    "                        right = detection[3] * cols\n",
    "                        bottom = detection[2] * rows\n",
    "                        rects.append([int(left), int(top), int(right) - int(left), int(bottom) - int(top)])\n",
    "                        cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (23, 230, 210), thickness=2)\n",
    "\n",
    "                drawRects(frame, rects)\n",
    "\n",
    "                saveRects(rects, im_path, predictions)\n",
    "\n",
    "                fps.add_fps(frame)\n",
    "\n",
    "                cv2.imshow('frame', frame)\n",
    "\n",
    "                if cv2.waitKey(100) & 0xFF == ord('q'):\n",
    "                    break\n",
    "\n",
    "            cv2.destroyAllWindows()    \n",
    "    \n",
    "    if write_to_file:\n",
    "        if dataset == 'VIDEO':\n",
    "            with open(preds_folder + 'VIDEO_val_predictions_SSD.json', 'w') as outfile:\n",
    "                json.dump(predictions, outfile)\n",
    "        elif dataset == 'FLIR':\n",
    "            with open(preds_folder + 'FLIR_val_predictions_SSD.json', 'w') as outfile:\n",
    "                json.dump(predictions, outfile)\n",
    "        else:\n",
    "            assert(False)\n",
    "        \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = plain_SSD_predict('FLIR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TSMO_SSD_predict(dataset, write_to_file = False):\n",
    "    path = r'C:\\Users\\Yuriy\\Net2//'\n",
    "\n",
    "    if dataset == 'VIDEO':\n",
    "        PATH_TO_CKPT = path + '/ssd_mobilenet_v2_coco_2020_02_02/frozen_inference_graph.pb'\n",
    "        dataset_keys = list(video_dataset.keys())\n",
    "    elif dataset == 'FLIR':\n",
    "        PATH_TO_CKPT = path + '/ssd_mobilenet_v2_coco_2020_02_17/frozen_inference_graph.pb'\n",
    "        dataset_keys = list(FLIR_dataset.keys())\n",
    "    else:\n",
    "        assert(False)\n",
    "\n",
    "    predictions = {}\n",
    "\n",
    "    fps = FpsCounter()\n",
    "\n",
    "    detection_graph = tf.Graph()\n",
    "    with detection_graph.as_default():\n",
    "        od_graph_def = tf.GraphDef()\n",
    "        with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "            serialized_graph = fid.read()\n",
    "            od_graph_def.ParseFromString(serialized_graph)\n",
    "            tf.import_graph_def(od_graph_def, name='')\n",
    "\n",
    "    with detection_graph.as_default():\n",
    "        with tf.Session(graph=detection_graph) as sess:\n",
    "\n",
    "            ind = -1\n",
    "            for im_path in dataset_keys:\n",
    "                fps.start()\n",
    "                ind += 1\n",
    "                if (ind < 0):\n",
    "                    continue\n",
    "                frame = cv2.imread(im_path)\n",
    "                im = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                cv2.imshow(\"im\", im)\n",
    "\n",
    "\n",
    "                thresholds, masks = full_method(im, L = 2**8, M=128)\n",
    "                N = 8\n",
    "                thresh_val = thresholds[-1]\n",
    "                den = whiteDensity(im, n = N, val = thresh_val)  \n",
    "\n",
    "                sym = symm(den, 0.1)\n",
    "                sym = np.array([[sym[i] for j in range(N)] for i in range(len(sym))]).reshape(-1,) \n",
    "            #     sym = getImMask(im)\n",
    "                sym_im = np.array([[im[i,j] for j in range(im.shape[1])]*sym for i in range(im.shape[0])], dtype = np.uint8)\n",
    "                cv2.imshow(\"symm_im\", sym_im)\n",
    "\n",
    "\n",
    "\n",
    "                regions, reg_masks = getRegionsAndMasks(im, sym)\n",
    "                rects = getRects(regions, reg_masks)        \n",
    "\n",
    "                frame_= frame.copy()\n",
    "                true_rects = []\n",
    "                for (x, y, w, h) in rects:\n",
    "                    frame = frame[y : y + h, x : x + w]\n",
    "                    rows = frame.shape[0]\n",
    "                    cols = frame.shape[1]\n",
    "                    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "                    image_np_expanded = np.expand_dims(frame, axis=0)\n",
    "                    image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "                    # Each box represents a part of the image where a particular object was detected.\n",
    "                    boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "                    # Each score represent how level of confidence for each of the objects.\n",
    "                    # Score is shown on the result image, together with the class label.\n",
    "                    scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "                    classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "                    num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "\n",
    "                    # Using Actual detection.\n",
    "                    (boxes, scores, classes, num_detections) = sess.run(\n",
    "                        [boxes, scores, classes, num_detections],\n",
    "                        feed_dict={image_tensor: image_np_expanded})\n",
    "                    scores = np.squeeze(scores)\n",
    "\n",
    "                    if (num_detections>0):\n",
    "                        for i in range(0,int(num_detections[0])):\n",
    "                            if scores[i] < 0.2 :\n",
    "                                continue\n",
    "                            true_rects.append((x, y, w, h))\n",
    "\n",
    "                    frame = frame_.copy()\n",
    "                rects = true_rects\n",
    "                drawRects(frame, rects)\n",
    "                saveRects(rects, im_path, predictions)\n",
    "\n",
    "            #     drawContours(frame, regions, reg_masks)    \n",
    "                fps.add_fps(frame)\n",
    "                cv2.imshow('frame', frame)\n",
    "\n",
    "\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "\n",
    "            cv2.destroyAllWindows() \n",
    "            \n",
    "    if write_to_file:\n",
    "        if dataset == 'VIDEO':\n",
    "            with open(preds_folder + 'VIDEO_val_predictions_SSD.json', 'w') as outfile:\n",
    "                json.dump(predictions, outfile)\n",
    "        elif dataset == 'FLIR':\n",
    "            with open(preds_folder + 'FLIR_val_predictions_SSD.json', 'w') as outfile:\n",
    "                json.dump(predictions, outfile)\n",
    "        else:\n",
    "            assert(False)\n",
    "        \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = TSMO_SSD_predict('FLIR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(preds_folder + 'VIDEO_val_predictions_TSMO_SSD.json', 'w') as outfile:\n",
    "    json.dump(predictions, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
